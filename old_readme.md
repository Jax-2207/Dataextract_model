# Multimodal RAG System

A powerful Retrieval-Augmented Generation (RAG) system that supports multiple file types including PDFs, images, audio, and video.

## ğŸš€ Tech Stack

| Layer | Technology |
|-------|------------|
| Backend API | FastAPI |
| Language | Python |
| OCR | PaddleOCR (+ Tesseract fallback) |
| Documents | PyMuPDF, Apache Tika |
| Audio/Video | Whisper, FFmpeg |
| Vision | OpenCV, BLIP, OpenCLIP |
| Embeddings | BGE / MiniLM |
| Vector DB | FAISS |
| LLM | LLaMA 3.1 (local via Ollama) |
| Metadata DB | PostgreSQL |

## ğŸ“ Project Structure

```
multimodal-rag/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # FastAPI entry
â”‚   â”œâ”€â”€ config.py                # Configuration settings
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ upload.py            # File upload endpoints
â”‚   â”‚   â””â”€â”€ query.py             # RAG query endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ router.py            # File type detection
â”‚   â”‚   â”œâ”€â”€ ingestion.py         # Pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ chunking.py          # Text chunking
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # Embedding generation
â”‚   â”‚   â””â”€â”€ llm.py               # LLM integration
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ pdf.py               # PDF processing
â”‚   â”‚   â”œâ”€â”€ audio.py             # Audio transcription
â”‚   â”‚   â”œâ”€â”€ video.py             # Video processing
â”‚   â”‚   â””â”€â”€ image.py             # Image processing
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # FAISS vector store
â”‚   â”‚   â””â”€â”€ metadata_db.py       # PostgreSQL metadata
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ocr.py               # OCR utilities
â”‚       â””â”€â”€ text_cleaner.py      # Text preprocessing
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/                 # Uploaded files
â”‚   â”œâ”€â”€ processed/               # Processed data
â”‚   â””â”€â”€ faiss/                   # FAISS index storage
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation

### 1. Create Virtual Environment

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Install Additional Requirements

**FFmpeg** (for audio/video processing):
- Windows: Download from https://ffmpeg.org/download.html
- Linux: `sudo apt install ffmpeg`
- Mac: `brew install ffmpeg`

**Tesseract OCR** (fallback OCR):
- Windows: Download installer from https://github.com/UB-Mannheim/tesseract/wiki
- Linux: `sudo apt install tesseract-ocr`
- Mac: `brew install tesseract`

**Ollama** (for local LLM):
- Download from https://ollama.ai
- Pull LLaMA model: `ollama pull llama3.1`

### 4. Setup PostgreSQL (Optional)

```bash
# Create database
createdb multimodal_rag

# Set environment variables
export POSTGRES_HOST=localhost
export POSTGRES_PORT=5432
export POSTGRES_DB=multimodal_rag
export POSTGRES_USER=postgres
export POSTGRES_PASSWORD=your_password
```

## ğŸš€ Running the Application

### Start Ollama (for LLM)
```bash
ollama serve
```

### Start the API
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Access the API
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc
- Health Check: http://localhost:8000/health

## ğŸ“ API Endpoints

### Upload Files

```bash
# Upload single file
curl -X POST "http://localhost:8000/upload/" \
  -H "accept: application/json" \
  -F "file=@document.pdf"

# Simple extraction (no vector storage)
curl -X POST "http://localhost:8000/upload/simple" \
  -H "accept: application/json" \
  -F "file=@image.png"
```

### Query

```bash
# Ask a question
curl -X POST "http://localhost:8000/query/" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the main topic of the document?"}'
```

## ğŸ“‚ Supported File Types

| Type | Extensions |
|------|------------|
| PDF | .pdf |
| Images | .jpg, .jpeg, .png |
| Audio | .mp3, .wav |
| Video | .mp4 |

## ğŸ”§ Configuration

Edit `app/config.py` to customize:

- **Embedding model**: Change `EMBEDDING_MODEL`
- **Chunk size**: Adjust `CHUNK_SIZE` and `CHUNK_OVERLAP`
- **LLM model**: Update `OLLAMA_MODEL`
- **OCR settings**: Toggle `USE_PADDLEOCR`

## ğŸ“Š Features

- âœ… Multi-format document processing
- âœ… OCR for scanned documents (PaddleOCR + Tesseract)
- âœ… Audio/Video transcription (Whisper)
- âœ… Image captioning (BLIP)
- âœ… Semantic chunking with overlap
- âœ… BGE embeddings for semantic search
- âœ… FAISS vector storage
- âœ… Local LLM integration (Ollama)
- âœ… PostgreSQL metadata tracking
- âœ… RESTful API with FastAPI

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“„ License

MIT License
