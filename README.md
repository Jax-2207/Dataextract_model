<div align="center">

# ğŸ“ DataExtract RAG

### Intelligent Educational Content Processing Platform

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![Groq](https://img.shields.io/badge/Groq-LLaMA_3.3_70B-FF6B35?style=for-the-badge)](https://groq.com)
[![MongoDB](https://img.shields.io/badge/MongoDB-47A248?style=for-the-badge&logo=mongodb&logoColor=white)](https://mongodb.com)

*A self-learning multimodal RAG system with confidence scoring, internet fallback, and cloud-powered AI*

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Installation](#-installation) â€¢ [API](#-api-endpoints) â€¢ [Demo](#-demo)

</div>

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ§  Smart RAG with Self-Learning
- **Confidence Scoring** - Every answer shows 0-100% confidence
- **Internet Fallback** - Uses LLM knowledge when local docs fail  
- **Auto-Learning** - Saves high-confidence answers for future use
- **Source Attribution** - Shows where each answer came from

</td>
<td width="50%">

### â˜ï¸ Cloud-Powered AI (FREE Tier)
- **Groq LLaMA 3.3 70B** - Ultra-fast inference (14,400 req/day)
- **Groq Whisper Large-v3** - Accurate transcription
- **Cohere Embed v3** - State-of-the-art embeddings (1024d)
- **Automatic Fallback** - Local processing if cloud unavailable

</td>
</tr>
<tr>
<td width="50%">

### ğŸ“„ Multimodal Processing
- **PDFs** - Text extraction + OCR for scans
- **Images** - OCR + BLIP captioning  
- **Audio** - Whisper transcription
- **Video** - Frame extraction + audio transcription

</td>
<td width="50%">

### ğŸ¯ Educational Focus
- **Teacher Persona** - Friendly, helpful responses
- **Step-by-Step** - Clear explanations with examples
- **Code Blocks** - Syntax-highlighted code snippets
- **Math Support** - Formatted equations and solutions

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

### System Overview

```mermaid
flowchart TB
    subgraph Client["ğŸ–¥ï¸ Client"]
        UI[Web Interface]
    end
    
    subgraph API["âš¡ FastAPI Backend"]
        Upload["/upload"]
        Query["/query"]
        Internet["/query/internet"]
    end
    
    subgraph Processing["ğŸ”§ Processing Pipeline"]
        Router[File Router]
        PDF[PDF Processor]
        IMG[Image Processor]
        AUD[Audio Processor]
        VID[Video Processor]
        Chunk[Chunking Engine]
    end
    
    subgraph AI["ğŸ§  AI Services"]
        subgraph Cloud["â˜ï¸ Cloud (Primary)"]
            GroqLLM[Groq LLaMA 70B]
            GroqWhisper[Groq Whisper]
            Cohere[Cohere Embeddings]
        end
        subgraph Local["ğŸ’» Local (Fallback)"]
            Ollama[Ollama LLaMA]
            LocalWhisper[Local Whisper]
            BGE[BGE Embeddings]
        end
    end
    
    subgraph Storage["ğŸ’¾ Storage"]
        FAISS[(FAISS Vector Store)]
        MongoDB[(MongoDB Atlas)]
        Learned[(Learned Answers)]
    end
    
    UI --> Upload & Query & Internet
    Upload --> Router
    Router --> PDF & IMG & AUD & VID
    PDF & IMG & AUD & VID --> Chunk
    Chunk --> Cohere --> FAISS
    Query --> FAISS --> GroqLLM --> UI
    Internet --> GroqLLM --> Learned
```

### Smart Query Flow

```mermaid
flowchart LR
    A[ğŸ“ Question] --> B{ğŸ” Check Learned DB}
    B -->|Found| C[âœ… Return Saved Answer]
    B -->|Not Found| D[ğŸ“„ Search Local Docs]
    D --> E[ğŸ¤– Generate + Score]
    E --> F{Confidence â‰¥ 60%?}
    F -->|Yes| G[âœ… Return Answer]
    F -->|No| H[âš ï¸ Show + Offer Internet]
    H --> I{User Clicks Search}
    I -->|Yes| J[ğŸŒ Internet Search]
    J --> K{Confidence â‰¥ 90%?}
    K -->|Yes| L[ğŸ’¾ Save to Learned DB]
    K -->|No| M[ğŸ“¤ Return Answer]
    L --> M
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **API** | FastAPI | High-performance async REST API |
| **LLM** | Groq (LLaMA 3.3 70B) | Ultra-fast cloud inference |
| **Transcription** | Groq Whisper Large-v3 | Accurate audio/video transcription |
| **Embeddings** | Cohere Embed v3 | 1024-dimensional semantic embeddings |
| **Vector Store** | FAISS | Efficient similarity search |
| **Database** | MongoDB Atlas | Document metadata + learned answers |
| **OCR** | PaddleOCR + Tesseract | Text extraction from images |
| **Vision** | OpenCV + BLIP | Image processing + captioning |
| **Audio/Video** | FFmpeg + Whisper | Media processing |

### Local Fallback Stack
| Component | Fallback |
|-----------|----------|
| LLM | Ollama (LLaMA 3.2 3B) |
| Whisper | Local Whisper Tiny |
| Embeddings | BGE-base-en (768d) |

---

## ğŸ“ Project Structure

```
DataExtract_model/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # FastAPI entry + health checks
â”‚   â”œâ”€â”€ config.py                  # Configuration + cloud API settings
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ upload.py              # File upload endpoints
â”‚   â”‚   â””â”€â”€ query.py               # Smart RAG query endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ router.py              # File type detection
â”‚   â”‚   â”œâ”€â”€ ingestion.py           # Processing pipeline
â”‚   â”‚   â”œâ”€â”€ chunking.py            # Semantic text chunking
â”‚   â”‚   â”œâ”€â”€ embeddings.py          # Cohere/BGE embeddings
â”‚   â”‚   â””â”€â”€ llm.py                 # Groq/Ollama LLM + confidence scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ pdf.py                 # PDF text + OCR extraction
â”‚   â”‚   â”œâ”€â”€ audio.py               # Audio transcription
â”‚   â”‚   â”œâ”€â”€ video.py               # Video frame + audio processing
â”‚   â”‚   â””â”€â”€ image.py               # Image OCR + captioning
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ vector_store.py        # FAISS vector operations
â”‚   â”‚   â”œâ”€â”€ metadata_db.py         # MongoDB metadata
â”‚   â”‚   â””â”€â”€ learned_answers.py     # Self-learning answer storage
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ocr.py                 # PaddleOCR utilities
â”‚       â””â”€â”€ text_cleaner.py        # Text preprocessing
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html                 # Web interface
â”‚   â”œâ”€â”€ app.js                     # Frontend JavaScript
â”‚   â””â”€â”€ styles.css                 # Modern dark theme
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/                   # Uploaded files
â”‚   â”œâ”€â”€ processed/                 # Extracted content
â”‚   â””â”€â”€ faiss/                     # Vector index storage
â”‚
â”œâ”€â”€ .env                           # API keys (not in git)
â”œâ”€â”€ .env.example                   # Environment template
â””â”€â”€ requirements.txt               # Python dependencies
```

---

## ğŸš€ Installation

### Prerequisites
- Python 3.10+
- FFmpeg (for audio/video)
- MongoDB Atlas account (free)
- Groq API key (free)
- Cohere API key (free)

### 1. Clone & Setup

```bash
git clone https://github.com/yourusername/dataextract-rag.git
cd dataextract-rag

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Get FREE API Keys

| Service | Link | Free Tier |
|---------|------|-----------|
| **Groq** | [console.groq.com](https://console.groq.com) | 14,400 requests/day |
| **Cohere** | [dashboard.cohere.com](https://dashboard.cohere.com) | 1,000 requests/min |
| **MongoDB** | [cloud.mongodb.com](https://cloud.mongodb.com) | 512MB free |

### 3. Configure Environment

```bash
# Copy template
cp .env.example .env

# Edit .env with your keys
GROQ_API_KEY=your_groq_key
COHERE_API_KEY=your_cohere_key
MONGODB_URI=your_mongodb_connection_string
```

### 4. Run the Server

```bash
python -m uvicorn app.main:app --reload
```

Open **http://localhost:8000** in your browser! ğŸ‰

---

## ğŸ“¡ API Endpoints

### Upload Documents

```bash
# Upload file for processing
curl -X POST "http://localhost:8000/upload/" \
  -F "file=@lecture.pdf"
```

**Response:**
```json
{
  "file_name": "lecture.pdf",
  "file_type": "pdf",
  "chunks_created": 45,
  "status": "success"
}
```

### Smart Query (with Confidence)

```bash
curl -X POST "http://localhost:8000/query/" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is machine learning?"}'
```

**Response:**
```json
{
  "question": "What is machine learning?",
  "answer": "Machine learning is a subset of AI...",
  "confidence_score": 85,
  "source": "local_db",
  "offer_internet": false,
  "sources": [{"file": "lecture.pdf", "chunk_id": 12}]
}
```

### Internet Search (Fallback)

```bash
curl -X POST "http://localhost:8000/query/internet" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is quantum computing?"}'
```

**Response:**
```json
{
  "answer": "Quantum computing uses quantum mechanics...",
  "confidence_score": 92,
  "source": "internet",
  "saved_to_db": true
}
```

---

## ğŸ–¼ï¸ Demo

### Dashboard
The modern dark-themed interface shows:
- ğŸ“Š System health status
- ğŸ“ˆ Vector store statistics  
- ğŸ”„ Real-time activity log

### Query Interface
- ğŸ’¬ Chat-style Q&A
- ğŸ·ï¸ Confidence badges (High/Medium/Low)
- ğŸŒ Internet search button
- ğŸ“„ Source attribution

### Confidence Scoring
| Score | Badge | Action |
|-------|-------|--------|
| 80-100% | ğŸŸ¢ High | Return answer |
| 60-79% | ğŸŸ¡ Medium | Return answer |
| <60% | ğŸ”´ Low | Offer internet search |

---

## ğŸ“‚ Supported File Types

| Type | Extensions | Processing |
|------|------------|------------|
| **PDF** | `.pdf` | Text extraction + OCR |
| **Images** | `.jpg`, `.png` | OCR + BLIP captioning |
| **Audio** | `.mp3`, `.wav` | Whisper transcription |
| **Video** | `.mp4` | Frame + audio extraction |

---

## âš™ï¸ Configuration

Key settings in `.env`:

```env
# Cloud APIs (FREE)
GROQ_API_KEY=gsk_xxx
COHERE_API_KEY=xxx

# Database
MONGODB_URI=mongodb+srv://...

# Toggle cloud/local
USE_CLOUD_LLM=true
USE_CLOUD_WHISPER=true
USE_CLOUD_EMBEDDINGS=true
```

Thresholds in `app/api/query.py`:
```python
LOCAL_DB_THRESHOLD = 60   # Below this, offer internet
LEARNING_THRESHOLD = 90   # Above this, save to DB
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request


<div align="center">

**Made with â¤ï¸ for Education**

[â¬† Back to Top](#-dataextract-rag)

</div>
